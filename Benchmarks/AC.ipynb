{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9d075ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class PolicyGradient(object):\n",
    "    def __init__(self, env, num_iterations=300, batch_size=2000, max_ep_len=200, output_path=\"../results/\"):\n",
    "        self.output_path = output_path\n",
    "        if not os.path.exists(output_path):\n",
    "            os.makedirs(output_path)\n",
    "        self.env = env\n",
    "        self.observation_dim = self.env.observation_space.shape[0]\n",
    "        self.action_dim = self.env.action_space.n\n",
    "        self.gamma = 0.9\n",
    "        self.num_iterations = num_iterations\n",
    "        self.batch_size = batch_size\n",
    "        self.max_ep_len = max_ep_len\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=3e-2)\n",
    "        self.policy_net = PolicyNet(input_size=self.observation_dim, output_size=self.action_dim)\n",
    "        self.baseline_net = BaselineNet(input_size=self.observation_dim, output_size=1)\n",
    "        \n",
    "    def play_games(self, env=None, num_episodes = None):\n",
    "        episode = 0\n",
    "        episode_rewards = []\n",
    "        paths = []\n",
    "        t = 0\n",
    "        if not env:\n",
    "            env = self.env\n",
    "\n",
    "        while (num_episodes or t < self.batch_size):\n",
    "            state = env.reset()\n",
    "            states, actions, rewards = [], [], []\n",
    "            episode_reward = 0\n",
    "\n",
    "            for step in range(self.max_ep_len):\n",
    "                states.append(state)\n",
    "                action = self.policy_net.sampel_action(np.atleast_2d(state))[0]\n",
    "                state, reward, done, _ = env.step(action)\n",
    "                actions.append(action)\n",
    "                rewards.append(reward)\n",
    "                episode_reward += reward\n",
    "                t += 1\n",
    "                env.render()\n",
    "                if (done or step == self.max_ep_len-1):\n",
    "                    episode_rewards.append(episode_reward)\n",
    "                    break\n",
    "                if (not num_episodes) and t == self.batch_size:\n",
    "                    break\n",
    "\n",
    "            path = {\"observation\": np.array(states),\n",
    "                    \"reward\": np.array(rewards),\n",
    "                    \"action\": np.array(actions)}\n",
    "            paths.append(path)\n",
    "            episode += 1\n",
    "            if num_episodes and episode >= num_episodes:\n",
    "                break\n",
    "        return paths, episode_rewards\n",
    "    \n",
    "    def get_advantage(self, returns, observations):\n",
    "        values = self.baseline_net.forward(observations).numpy()\n",
    "        advantages = returns - values\n",
    "        advantages = (advantages-np.mean(advantages)) / np.sqrt(np.sum(advantages**2))\n",
    "        return advantages\n",
    "    \n",
    "    def update_policy(self, observations, actions, advantages):\n",
    "        observations = tf.convert_to_tensor(observations)\n",
    "        actions = tf.convert_to_tensor(actions)\n",
    "        advantages = tf.convert_to_tensor(advantages)\n",
    "        with tf.GradientTape() as tape:\n",
    "            log_prob = self.policy_net.action_distribution(observations).log_prob(actions)\n",
    "            loss = -tf.math.reduce_mean(log_prob * tf.cast(advantages, tf.float32))\n",
    "        grads = tape.gradient(loss, self.policy_net.model.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.policy_net.model.trainable_weights))\n",
    "        \n",
    "    def train(self):\n",
    "        all_total_rewards = []\n",
    "        averaged_total_rewards = []\n",
    "        for t in range(self.num_iterations):\n",
    "            paths, total_rewards = self.play_games()\n",
    "            all_total_rewards.extend(total_rewards)\n",
    "            observations = np.concatenate([path[\"observation\"] for path in paths])\n",
    "            actions = np.concatenate([path[\"action\"] for path in paths])\n",
    "            returns = self.get_returns(paths)\n",
    "            advantages = self.get_advantage(returns, observations)\n",
    "            self.baseline_net.update(observations=observations, target=returns)\n",
    "            self.update_policy(observations, actions, advantages)\n",
    "            avg_reward = np.mean(total_rewards)\n",
    "            averaged_total_rewards.append(avg_reward)\n",
    "            print(\"Average reward for batch {}: {:04.2f}\".format(t,avg_reward))\n",
    "        print(\"Training complete\")\n",
    "        np.save(self.output_path+ \"rewards.npy\", averaged_total_rewards)\n",
    "        export_plot(averaged_total_rewards, \"Reward\", \"CartPole-v0\", self.output_path + \"rewards.png\")\n",
    "        \n",
    "    def eval(self, env, num_episodes=1):\n",
    "        paths, rewards = self.play_games(env, num_episodes)\n",
    "        avg_reward = np.mean(rewards)\n",
    "        print(\"Average eval reward: {:04.2f}\".format(avg_reward))\n",
    "        return avg_reward\n",
    "\n",
    "    \n",
    "    def get_returns(self, paths):\n",
    "        all_returns = []\n",
    "        for path in paths:\n",
    "            rewards = path[\"reward\"]\n",
    "            returns = []\n",
    "            reversed_rewards = np.flip(rewards,0)\n",
    "            g_t = 0\n",
    "            for r in reversed_rewards:\n",
    "                g_t = r + self.gamma*g_t\n",
    "                returns.insert(0, g_t)\n",
    "            all_returns.append(returns)\n",
    "        returns = np.concatenate(all_returns)\n",
    "        return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "989375e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "\n",
    "class AC():\n",
    "\n",
    "    def __init__(self, GAMMA=0.99, UB=1, LB = -1, CLR = 1e-3, ALR = 1e-3):\n",
    "\n",
    "        self.num_states = 3\n",
    "        self.num_actions = 1\n",
    "        self.GAMMA = GAMMA\n",
    "        self.UPPER_BOUND = UB\n",
    "        self.LOWER_BOUND = LB\n",
    "        self.CRITIC_LR = CLR\n",
    "        self.ACTOR_LR = ALR\n",
    "\n",
    "    def Actor(self):\n",
    "\n",
    "        inputs = tf.keras.layers.Input(shape=(self.num_states,))\n",
    "        out = tf.keras.layers.Dense(64, activation=\"relu\")(inputs)\n",
    "        outputs = tf.keras.layers.Dense(self.num_actions)(out)\n",
    "\n",
    "        model = tf.keras.Model(inputs, outputs)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def make_distribution(self, actor_model, observations):\n",
    "        \n",
    "        logits = actor_model(observations)\n",
    "\n",
    "        return tfp.distributions.Categorical(logits=logits)\n",
    "    \n",
    "    def sample_action(self, actor_model, observations):\n",
    "        \n",
    "        sampled_actions = self.make_distribution(actor_model, observations).sample().numpy()\n",
    "        \n",
    "        return sampled_actions\n",
    "    \n",
    "\n",
    "    def Critic(self):\n",
    "        state_input = tf.keras.layers.Input(shape=(self.num_states))\n",
    "        \n",
    "        state_out = tf.keras.layers.Dense(16, activation=\"relu\")(state_input)\n",
    "        state_out = tf.keras.layers.Dense(32, activation=\"relu\")(state_out)\n",
    "\n",
    "        outputs = tf.keras.layers.Dense(1)(state_out)\n",
    "\n",
    "        model = tf.keras.Model(state_input, outputs)\n",
    "        \n",
    "        return model\n",
    "\n",
    "\n",
    "    def initialize(self):\n",
    "        \n",
    "        actor = self.Actor()\n",
    "        \n",
    "        critic = self.Critic()\n",
    "        \n",
    "        critic_optimizer = tf.keras.optimizers.Adam(self.CRITIC_LR)\n",
    "        actor_optimizer = tf.keras.optimizers.Adam(self.ACTOR_LR)\n",
    "        \n",
    "        \n",
    "        return [actor, critic, critic_optimizer, actor_optimizer]\n",
    "    \n",
    "class Buffer:\n",
    "    def __init__(self, agent, batch_size=64):\n",
    "        # Number of \"experiences\" to remember\n",
    "        self.batch_size = batch_size\n",
    "        self.buffer_counter = 0\n",
    "\n",
    "        self.states = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.next_states = []\n",
    "\n",
    "    def record(self, obs_tuple):\n",
    "        # Set index to zero if buffer_capacity is exceeded,\n",
    "        # replacing old records\n",
    "        \n",
    "        self.states.insert(0, obs_tuple[0])\n",
    "        self.actions.insert(0, obs_tuple[1])\n",
    "        self.rewards.insert(0, obs_tuple[2])\n",
    "        self.next_states.insert(0, obs_tuple[3])\n",
    "    \n",
    "    def forget(self):\n",
    "        \n",
    "        self.states = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.next_states = []\n",
    "        \n",
    "\n",
    "    @tf.function\n",
    "    def update(self, state_batch, action_batch, reward_batch, next_state_batch):\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            \n",
    "            b = critic_model(state_batch, training=True)\n",
    "            \n",
    "            critic_loss = tf.math.reduce_mean(tf.math.square(reward_batch - b))\n",
    "\n",
    "        critic_grad = tape.gradient(critic_loss, critic_model.trainable_variables)\n",
    "        critic_optimizer.apply_gradients(\n",
    "            zip(critic_grad, critic_model.trainable_variables)\n",
    "        )\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            \n",
    "            log_prob = agent.make_distribution(actor_model, state_batch).log_prob(action_batch)\n",
    "            \n",
    "            b = critic_model(state_batch, training=True)\n",
    "            \n",
    "            actor_loss = -tf.math.reduce_mean(log_prob * tf.cast(reward_batch - b, tf.float32))\n",
    "\n",
    "        actor_grad = tape.gradient(actor_loss, actor_model.trainable_variables)\n",
    "        actor_optimizer.apply_gradients(\n",
    "            zip(actor_grad, actor_model.trainable_variables)\n",
    "        )\n",
    "\n",
    "        \n",
    "    def learn(self, agent):\n",
    "        # Get sampling range\n",
    "        \n",
    "        for i in range(len(self.rewards)//self.batch_size):\n",
    "            state_batch = tf.convert_to_tensor(self.states[i*self.batch_size:((i+1)*self.batch_size)+1])\n",
    "            action_batch = tf.convert_to_tensor(self.actions[i*self.batch_size:((i+1)*self.batch_size)+1])\n",
    "            reward_batch = tf.convert_to_tensor(self.rewards[i*self.batch_size:((i+1)*self.batch_size)+1])\n",
    "            reward_batch = tf.cast(reward_batch, dtype=tf.float32)\n",
    "            next_state_batch = tf.convert_to_tensor(self.next_states[i*self.batch_size:((i+1)*self.batch_size)+1])\n",
    "    \n",
    "            self.update(agent, state_batch, action_batch, reward_batch, next_state_batch)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e14f09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For episode 0 the finale reward-to-go is 17.0\n",
      "For episode 10 the finale reward-to-go is 15.0\n",
      "For episode 20 the finale reward-to-go is 10.0\n",
      "For episode 30 the finale reward-to-go is 9.0\n",
      "For episode 40 the finale reward-to-go is 10.0\n",
      "For episode 50 the finale reward-to-go is 11.0\n",
      "For episode 60 the finale reward-to-go is 10.0\n",
      "For episode 70 the finale reward-to-go is 10.0\n",
      "For episode 80 the finale reward-to-go is 9.0\n",
      "For episode 90 the finale reward-to-go is 9.0\n",
      "For episode 100 the finale reward-to-go is 12.0\n",
      "For episode 110 the finale reward-to-go is 44.0\n",
      "For episode 120 the finale reward-to-go is 10.0\n",
      "For episode 130 the finale reward-to-go is 9.0\n",
      "For episode 140 the finale reward-to-go is 9.0\n",
      "For episode 150 the finale reward-to-go is 10.0\n",
      "For episode 160 the finale reward-to-go is 9.0\n",
      "For episode 170 the finale reward-to-go is 8.0\n",
      "For episode 180 the finale reward-to-go is 9.0\n",
      "For episode 190 the finale reward-to-go is 10.0\n",
      "For episode 200 the finale reward-to-go is 10.0\n",
      "For episode 210 the finale reward-to-go is 9.0\n",
      "For episode 220 the finale reward-to-go is 9.0\n",
      "For episode 230 the finale reward-to-go is 10.0\n",
      "For episode 240 the finale reward-to-go is 8.0\n",
      "For episode 250 the finale reward-to-go is 10.0\n",
      "For episode 260 the finale reward-to-go is 9.0\n",
      "For episode 270 the finale reward-to-go is 10.0\n",
      "For episode 280 the finale reward-to-go is 9.0\n",
      "For episode 290 the finale reward-to-go is 8.0\n",
      "For episode 300 the finale reward-to-go is 8.0\n",
      "For episode 310 the finale reward-to-go is 9.0\n",
      "For episode 320 the finale reward-to-go is 10.0\n",
      "For episode 330 the finale reward-to-go is 10.0\n",
      "For episode 340 the finale reward-to-go is 9.0\n",
      "For episode 350 the finale reward-to-go is 8.0\n",
      "For episode 360 the finale reward-to-go is 10.0\n",
      "For episode 370 the finale reward-to-go is 10.0\n",
      "For episode 380 the finale reward-to-go is 8.0\n",
      "For episode 390 the finale reward-to-go is 9.0\n",
      "For episode 400 the finale reward-to-go is 8.0\n",
      "For episode 410 the finale reward-to-go is 10.0\n",
      "For episode 420 the finale reward-to-go is 10.0\n",
      "For episode 430 the finale reward-to-go is 9.0\n",
      "For episode 440 the finale reward-to-go is 10.0\n",
      "For episode 450 the finale reward-to-go is 10.0\n",
      "For episode 460 the finale reward-to-go is 8.0\n",
      "For episode 470 the finale reward-to-go is 9.0\n",
      "For episode 480 the finale reward-to-go is 10.0\n",
      "For episode 490 the finale reward-to-go is 8.0\n",
      "For episode 500 the finale reward-to-go is 9.0\n",
      "For episode 510 the finale reward-to-go is 10.0\n",
      "For episode 520 the finale reward-to-go is 10.0\n",
      "For episode 530 the finale reward-to-go is 10.0\n",
      "For episode 540 the finale reward-to-go is 9.0\n",
      "For episode 550 the finale reward-to-go is 10.0\n",
      "For episode 560 the finale reward-to-go is 10.0\n",
      "For episode 570 the finale reward-to-go is 10.0\n",
      "For episode 580 the finale reward-to-go is 10.0\n",
      "For episode 590 the finale reward-to-go is 9.0\n",
      "For episode 600 the finale reward-to-go is 10.0\n",
      "For episode 610 the finale reward-to-go is 10.0\n",
      "For episode 620 the finale reward-to-go is 9.0\n",
      "For episode 630 the finale reward-to-go is 9.0\n",
      "For episode 640 the finale reward-to-go is 9.0\n",
      "For episode 650 the finale reward-to-go is 9.0\n",
      "For episode 660 the finale reward-to-go is 9.0\n",
      "For episode 670 the finale reward-to-go is 10.0\n",
      "For episode 680 the finale reward-to-go is 11.0\n",
      "For episode 690 the finale reward-to-go is 9.0\n",
      "For episode 700 the finale reward-to-go is 10.0\n",
      "For episode 710 the finale reward-to-go is 8.0\n",
      "For episode 720 the finale reward-to-go is 11.0\n",
      "For episode 730 the finale reward-to-go is 8.0\n",
      "For episode 740 the finale reward-to-go is 9.0\n",
      "For episode 750 the finale reward-to-go is 10.0\n",
      "For episode 760 the finale reward-to-go is 10.0\n",
      "For episode 770 the finale reward-to-go is 10.0\n",
      "For episode 780 the finale reward-to-go is 9.0\n",
      "For episode 790 the finale reward-to-go is 11.0\n",
      "For episode 800 the finale reward-to-go is 9.0\n",
      "For episode 810 the finale reward-to-go is 10.0\n",
      "For episode 820 the finale reward-to-go is 9.0\n",
      "For episode 830 the finale reward-to-go is 9.0\n",
      "For episode 840 the finale reward-to-go is 8.0\n",
      "For episode 850 the finale reward-to-go is 9.0\n",
      "For episode 860 the finale reward-to-go is 9.0\n",
      "For episode 870 the finale reward-to-go is 9.0\n",
      "For episode 880 the finale reward-to-go is 10.0\n",
      "For episode 890 the finale reward-to-go is 10.0\n",
      "For episode 900 the finale reward-to-go is 10.0\n",
      "For episode 910 the finale reward-to-go is 10.0\n",
      "For episode 920 the finale reward-to-go is 9.0\n",
      "For episode 930 the finale reward-to-go is 9.0\n",
      "For episode 940 the finale reward-to-go is 10.0\n",
      "For episode 950 the finale reward-to-go is 10.0\n",
      "For episode 960 the finale reward-to-go is 10.0\n",
      "For episode 970 the finale reward-to-go is 10.0\n",
      "For episode 980 the finale reward-to-go is 9.0\n",
      "For episode 990 the finale reward-to-go is 8.0\n",
      "For episode 1000 the finale reward-to-go is 10.0\n",
      "For episode 1010 the finale reward-to-go is 9.0\n",
      "For episode 1020 the finale reward-to-go is 10.0\n",
      "For episode 1030 the finale reward-to-go is 9.0\n",
      "For episode 1040 the finale reward-to-go is 10.0\n",
      "For episode 1050 the finale reward-to-go is 9.0\n",
      "For episode 1060 the finale reward-to-go is 9.0\n",
      "For episode 1070 the finale reward-to-go is 9.0\n",
      "For episode 1080 the finale reward-to-go is 10.0\n",
      "For episode 1090 the finale reward-to-go is 9.0\n",
      "For episode 1100 the finale reward-to-go is 10.0\n",
      "For episode 1110 the finale reward-to-go is 8.0\n",
      "For episode 1120 the finale reward-to-go is 9.0\n",
      "For episode 1130 the finale reward-to-go is 9.0\n",
      "For episode 1140 the finale reward-to-go is 10.0\n",
      "For episode 1150 the finale reward-to-go is 10.0\n",
      "For episode 1160 the finale reward-to-go is 8.0\n",
      "For episode 1170 the finale reward-to-go is 10.0\n",
      "For episode 1180 the finale reward-to-go is 9.0\n",
      "For episode 1190 the finale reward-to-go is 9.0\n",
      "For episode 1200 the finale reward-to-go is 10.0\n",
      "For episode 1210 the finale reward-to-go is 9.0\n",
      "For episode 1220 the finale reward-to-go is 9.0\n",
      "For episode 1230 the finale reward-to-go is 11.0\n",
      "For episode 1240 the finale reward-to-go is 9.0\n",
      "For episode 1250 the finale reward-to-go is 10.0\n",
      "For episode 1260 the finale reward-to-go is 9.0\n",
      "For episode 1270 the finale reward-to-go is 9.0\n",
      "For episode 1280 the finale reward-to-go is 8.0\n",
      "For episode 1290 the finale reward-to-go is 8.0\n",
      "For episode 1300 the finale reward-to-go is 9.0\n",
      "For episode 1310 the finale reward-to-go is 9.0\n",
      "For episode 1320 the finale reward-to-go is 8.0\n",
      "For episode 1330 the finale reward-to-go is 10.0\n",
      "For episode 1340 the finale reward-to-go is 9.0\n",
      "For episode 1350 the finale reward-to-go is 9.0\n",
      "For episode 1360 the finale reward-to-go is 9.0\n",
      "For episode 1370 the finale reward-to-go is 9.0\n",
      "For episode 1380 the finale reward-to-go is 9.0\n",
      "For episode 1390 the finale reward-to-go is 8.0\n",
      "For episode 1400 the finale reward-to-go is 8.0\n",
      "For episode 1410 the finale reward-to-go is 10.0\n",
      "For episode 1420 the finale reward-to-go is 10.0\n",
      "For episode 1430 the finale reward-to-go is 9.0\n",
      "For episode 1440 the finale reward-to-go is 8.0\n",
      "For episode 1450 the finale reward-to-go is 8.0\n",
      "For episode 1460 the finale reward-to-go is 10.0\n",
      "For episode 1470 the finale reward-to-go is 9.0\n",
      "For episode 1480 the finale reward-to-go is 10.0\n",
      "For episode 1490 the finale reward-to-go is 9.0\n",
      "For episode 1500 the finale reward-to-go is 9.0\n",
      "For episode 1510 the finale reward-to-go is 9.0\n",
      "For episode 1520 the finale reward-to-go is 8.0\n",
      "For episode 1530 the finale reward-to-go is 10.0\n",
      "For episode 1540 the finale reward-to-go is 9.0\n",
      "For episode 1550 the finale reward-to-go is 9.0\n",
      "For episode 1560 the finale reward-to-go is 8.0\n",
      "For episode 1570 the finale reward-to-go is 10.0\n",
      "For episode 1580 the finale reward-to-go is 8.0\n",
      "For episode 1590 the finale reward-to-go is 11.0\n",
      "For episode 1600 the finale reward-to-go is 10.0\n",
      "For episode 1610 the finale reward-to-go is 10.0\n",
      "For episode 1620 the finale reward-to-go is 9.0\n",
      "For episode 1630 the finale reward-to-go is 9.0\n",
      "For episode 1640 the finale reward-to-go is 8.0\n",
      "For episode 1650 the finale reward-to-go is 9.0\n",
      "For episode 1660 the finale reward-to-go is 9.0\n",
      "For episode 1670 the finale reward-to-go is 9.0\n",
      "For episode 1680 the finale reward-to-go is 8.0\n",
      "For episode 1690 the finale reward-to-go is 9.0\n",
      "For episode 1700 the finale reward-to-go is 9.0\n",
      "For episode 1710 the finale reward-to-go is 10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For episode 1720 the finale reward-to-go is 10.0\n",
      "For episode 1730 the finale reward-to-go is 10.0\n",
      "For episode 1740 the finale reward-to-go is 9.0\n",
      "For episode 1750 the finale reward-to-go is 9.0\n",
      "For episode 1760 the finale reward-to-go is 9.0\n",
      "For episode 1770 the finale reward-to-go is 10.0\n",
      "For episode 1780 the finale reward-to-go is 9.0\n",
      "For episode 1790 the finale reward-to-go is 10.0\n",
      "For episode 1800 the finale reward-to-go is 10.0\n",
      "For episode 1810 the finale reward-to-go is 9.0\n",
      "For episode 1820 the finale reward-to-go is 9.0\n",
      "For episode 1830 the finale reward-to-go is 8.0\n",
      "For episode 1840 the finale reward-to-go is 8.0\n",
      "For episode 1850 the finale reward-to-go is 9.0\n",
      "For episode 1860 the finale reward-to-go is 9.0\n",
      "For episode 1870 the finale reward-to-go is 8.0\n",
      "For episode 1880 the finale reward-to-go is 8.0\n",
      "For episode 1890 the finale reward-to-go is 9.0\n",
      "For episode 1900 the finale reward-to-go is 8.0\n",
      "For episode 1910 the finale reward-to-go is 10.0\n",
      "For episode 1920 the finale reward-to-go is 9.0\n",
      "For episode 1930 the finale reward-to-go is 8.0\n",
      "For episode 1940 the finale reward-to-go is 9.0\n",
      "For episode 1950 the finale reward-to-go is 10.0\n",
      "For episode 1960 the finale reward-to-go is 8.0\n",
      "For episode 1970 the finale reward-to-go is 9.0\n",
      "For episode 1980 the finale reward-to-go is 11.0\n",
      "For episode 1990 the finale reward-to-go is 9.0\n",
      "For episode 2000 the finale reward-to-go is 10.0\n",
      "For episode 2010 the finale reward-to-go is 10.0\n",
      "For episode 2020 the finale reward-to-go is 8.0\n",
      "For episode 2030 the finale reward-to-go is 9.0\n",
      "For episode 2040 the finale reward-to-go is 9.0\n",
      "For episode 2050 the finale reward-to-go is 10.0\n",
      "For episode 2060 the finale reward-to-go is 10.0\n",
      "For episode 2070 the finale reward-to-go is 9.0\n",
      "For episode 2080 the finale reward-to-go is 9.0\n",
      "For episode 2090 the finale reward-to-go is 9.0\n",
      "For episode 2100 the finale reward-to-go is 10.0\n",
      "For episode 2110 the finale reward-to-go is 10.0\n",
      "For episode 2120 the finale reward-to-go is 10.0\n",
      "For episode 2130 the finale reward-to-go is 11.0\n",
      "For episode 2140 the finale reward-to-go is 10.0\n",
      "For episode 2150 the finale reward-to-go is 10.0\n",
      "For episode 2160 the finale reward-to-go is 10.0\n",
      "For episode 2170 the finale reward-to-go is 10.0\n",
      "For episode 2180 the finale reward-to-go is 9.0\n",
      "For episode 2190 the finale reward-to-go is 8.0\n",
      "For episode 2200 the finale reward-to-go is 9.0\n",
      "For episode 2210 the finale reward-to-go is 10.0\n",
      "For episode 2220 the finale reward-to-go is 11.0\n",
      "For episode 2230 the finale reward-to-go is 10.0\n",
      "For episode 2240 the finale reward-to-go is 10.0\n",
      "For episode 2250 the finale reward-to-go is 9.0\n",
      "For episode 2260 the finale reward-to-go is 8.0\n",
      "For episode 2270 the finale reward-to-go is 9.0\n",
      "For episode 2280 the finale reward-to-go is 10.0\n",
      "For episode 2290 the finale reward-to-go is 9.0\n",
      "For episode 2300 the finale reward-to-go is 10.0\n",
      "For episode 2310 the finale reward-to-go is 8.0\n",
      "For episode 2320 the finale reward-to-go is 10.0\n",
      "For episode 2330 the finale reward-to-go is 10.0\n",
      "For episode 2340 the finale reward-to-go is 10.0\n",
      "For episode 2350 the finale reward-to-go is 10.0\n",
      "For episode 2360 the finale reward-to-go is 9.0\n",
      "For episode 2370 the finale reward-to-go is 9.0\n",
      "For episode 2380 the finale reward-to-go is 10.0\n",
      "For episode 2390 the finale reward-to-go is 8.0\n",
      "For episode 2400 the finale reward-to-go is 9.0\n",
      "For episode 2410 the finale reward-to-go is 10.0\n",
      "For episode 2420 the finale reward-to-go is 10.0\n",
      "For episode 2430 the finale reward-to-go is 10.0\n",
      "For episode 2440 the finale reward-to-go is 10.0\n",
      "For episode 2450 the finale reward-to-go is 10.0\n",
      "For episode 2460 the finale reward-to-go is 10.0\n",
      "For episode 2470 the finale reward-to-go is 9.0\n",
      "For episode 2480 the finale reward-to-go is 9.0\n",
      "For episode 2490 the finale reward-to-go is 10.0\n",
      "For episode 2500 the finale reward-to-go is 10.0\n",
      "For episode 2510 the finale reward-to-go is 9.0\n",
      "For episode 2520 the finale reward-to-go is 9.0\n",
      "For episode 2530 the finale reward-to-go is 10.0\n",
      "For episode 2540 the finale reward-to-go is 10.0\n",
      "For episode 2550 the finale reward-to-go is 9.0\n",
      "For episode 2560 the finale reward-to-go is 8.0\n",
      "For episode 2570 the finale reward-to-go is 10.0\n",
      "For episode 2580 the finale reward-to-go is 10.0\n",
      "For episode 2590 the finale reward-to-go is 10.0\n",
      "For episode 2600 the finale reward-to-go is 9.0\n",
      "For episode 2610 the finale reward-to-go is 10.0\n",
      "For episode 2620 the finale reward-to-go is 10.0\n",
      "For episode 2630 the finale reward-to-go is 10.0\n",
      "For episode 2640 the finale reward-to-go is 10.0\n",
      "For episode 2650 the finale reward-to-go is 9.0\n",
      "For episode 2660 the finale reward-to-go is 9.0\n",
      "For episode 2670 the finale reward-to-go is 10.0\n",
      "For episode 2680 the finale reward-to-go is 9.0\n",
      "For episode 2690 the finale reward-to-go is 9.0\n",
      "For episode 2700 the finale reward-to-go is 9.0\n",
      "For episode 2710 the finale reward-to-go is 10.0\n",
      "For episode 2720 the finale reward-to-go is 9.0\n",
      "For episode 2730 the finale reward-to-go is 8.0\n",
      "For episode 2740 the finale reward-to-go is 10.0\n",
      "For episode 2750 the finale reward-to-go is 9.0\n",
      "For episode 2760 the finale reward-to-go is 9.0\n",
      "For episode 2770 the finale reward-to-go is 9.0\n",
      "For episode 2780 the finale reward-to-go is 9.0\n",
      "For episode 2790 the finale reward-to-go is 9.0\n",
      "For episode 2800 the finale reward-to-go is 9.0\n",
      "For episode 2810 the finale reward-to-go is 9.0\n",
      "For episode 2820 the finale reward-to-go is 9.0\n",
      "For episode 2830 the finale reward-to-go is 10.0\n",
      "For episode 2840 the finale reward-to-go is 9.0\n",
      "For episode 2850 the finale reward-to-go is 10.0\n",
      "For episode 2860 the finale reward-to-go is 9.0\n",
      "For episode 2870 the finale reward-to-go is 9.0\n",
      "For episode 2880 the finale reward-to-go is 9.0\n",
      "For episode 2890 the finale reward-to-go is 10.0\n",
      "For episode 2900 the finale reward-to-go is 10.0\n",
      "For episode 2910 the finale reward-to-go is 10.0\n",
      "For episode 2920 the finale reward-to-go is 9.0\n",
      "For episode 2930 the finale reward-to-go is 9.0\n",
      "For episode 2940 the finale reward-to-go is 10.0\n",
      "For episode 2950 the finale reward-to-go is 10.0\n",
      "For episode 2960 the finale reward-to-go is 10.0\n",
      "For episode 2970 the finale reward-to-go is 9.0\n",
      "For episode 2980 the finale reward-to-go is 9.0\n",
      "For episode 2990 the finale reward-to-go is 10.0\n",
      "For episode 3000 the finale reward-to-go is 9.0\n",
      "For episode 3010 the finale reward-to-go is 10.0\n",
      "For episode 3020 the finale reward-to-go is 9.0\n",
      "For episode 3030 the finale reward-to-go is 10.0\n",
      "For episode 3040 the finale reward-to-go is 10.0\n",
      "For episode 3050 the finale reward-to-go is 10.0\n",
      "For episode 3060 the finale reward-to-go is 10.0\n",
      "For episode 3070 the finale reward-to-go is 10.0\n",
      "For episode 3080 the finale reward-to-go is 10.0\n",
      "For episode 3090 the finale reward-to-go is 8.0\n",
      "For episode 3100 the finale reward-to-go is 10.0\n",
      "For episode 3110 the finale reward-to-go is 10.0\n",
      "For episode 3120 the finale reward-to-go is 10.0\n",
      "For episode 3130 the finale reward-to-go is 10.0\n",
      "For episode 3140 the finale reward-to-go is 9.0\n",
      "For episode 3150 the finale reward-to-go is 10.0\n",
      "For episode 3160 the finale reward-to-go is 9.0\n",
      "For episode 3170 the finale reward-to-go is 9.0\n",
      "For episode 3180 the finale reward-to-go is 10.0\n",
      "For episode 3190 the finale reward-to-go is 9.0\n",
      "For episode 3200 the finale reward-to-go is 10.0\n",
      "For episode 3210 the finale reward-to-go is 8.0\n",
      "For episode 3220 the finale reward-to-go is 10.0\n",
      "For episode 3230 the finale reward-to-go is 10.0\n",
      "For episode 3240 the finale reward-to-go is 9.0\n",
      "For episode 3250 the finale reward-to-go is 10.0\n",
      "For episode 3260 the finale reward-to-go is 10.0\n",
      "For episode 3270 the finale reward-to-go is 11.0\n",
      "For episode 3280 the finale reward-to-go is 9.0\n",
      "For episode 3290 the finale reward-to-go is 8.0\n",
      "For episode 3300 the finale reward-to-go is 8.0\n",
      "For episode 3310 the finale reward-to-go is 10.0\n",
      "For episode 3320 the finale reward-to-go is 10.0\n",
      "For episode 3330 the finale reward-to-go is 10.0\n",
      "For episode 3340 the finale reward-to-go is 9.0\n",
      "For episode 3350 the finale reward-to-go is 11.0\n",
      "For episode 3360 the finale reward-to-go is 11.0\n",
      "For episode 3370 the finale reward-to-go is 10.0\n",
      "For episode 3380 the finale reward-to-go is 11.0\n",
      "For episode 3390 the finale reward-to-go is 11.0\n",
      "For episode 3400 the finale reward-to-go is 9.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For episode 3410 the finale reward-to-go is 10.0\n",
      "For episode 3420 the finale reward-to-go is 9.0\n",
      "For episode 3430 the finale reward-to-go is 10.0\n",
      "For episode 3440 the finale reward-to-go is 8.0\n",
      "For episode 3450 the finale reward-to-go is 9.0\n",
      "For episode 3460 the finale reward-to-go is 10.0\n",
      "For episode 3470 the finale reward-to-go is 8.0\n",
      "For episode 3480 the finale reward-to-go is 10.0\n",
      "For episode 3490 the finale reward-to-go is 9.0\n",
      "For episode 3500 the finale reward-to-go is 9.0\n",
      "For episode 3510 the finale reward-to-go is 9.0\n",
      "For episode 3520 the finale reward-to-go is 11.0\n",
      "For episode 3530 the finale reward-to-go is 9.0\n",
      "For episode 3540 the finale reward-to-go is 10.0\n",
      "For episode 3550 the finale reward-to-go is 9.0\n",
      "For episode 3560 the finale reward-to-go is 10.0\n",
      "For episode 3570 the finale reward-to-go is 8.0\n",
      "For episode 3580 the finale reward-to-go is 10.0\n",
      "For episode 3590 the finale reward-to-go is 9.0\n",
      "For episode 3600 the finale reward-to-go is 9.0\n",
      "For episode 3610 the finale reward-to-go is 10.0\n",
      "For episode 3620 the finale reward-to-go is 9.0\n",
      "For episode 3630 the finale reward-to-go is 10.0\n",
      "For episode 3640 the finale reward-to-go is 10.0\n",
      "For episode 3650 the finale reward-to-go is 10.0\n",
      "For episode 3660 the finale reward-to-go is 8.0\n",
      "For episode 3670 the finale reward-to-go is 8.0\n",
      "For episode 3680 the finale reward-to-go is 8.0\n",
      "For episode 3690 the finale reward-to-go is 10.0\n",
      "For episode 3700 the finale reward-to-go is 10.0\n",
      "For episode 3710 the finale reward-to-go is 8.0\n",
      "For episode 3720 the finale reward-to-go is 9.0\n",
      "For episode 3730 the finale reward-to-go is 9.0\n",
      "For episode 3740 the finale reward-to-go is 9.0\n",
      "For episode 3750 the finale reward-to-go is 10.0\n",
      "For episode 3760 the finale reward-to-go is 10.0\n",
      "For episode 3770 the finale reward-to-go is 11.0\n",
      "For episode 3780 the finale reward-to-go is 9.0\n",
      "For episode 3790 the finale reward-to-go is 11.0\n",
      "For episode 3800 the finale reward-to-go is 10.0\n",
      "For episode 3810 the finale reward-to-go is 10.0\n",
      "For episode 3820 the finale reward-to-go is 9.0\n",
      "For episode 3830 the finale reward-to-go is 9.0\n",
      "For episode 3840 the finale reward-to-go is 8.0\n",
      "For episode 3850 the finale reward-to-go is 10.0\n",
      "For episode 3860 the finale reward-to-go is 10.0\n",
      "For episode 3870 the finale reward-to-go is 10.0\n",
      "For episode 3880 the finale reward-to-go is 9.0\n",
      "For episode 3890 the finale reward-to-go is 10.0\n",
      "For episode 3900 the finale reward-to-go is 9.0\n",
      "For episode 3910 the finale reward-to-go is 10.0\n",
      "For episode 3920 the finale reward-to-go is 10.0\n",
      "For episode 3930 the finale reward-to-go is 9.0\n",
      "For episode 3940 the finale reward-to-go is 10.0\n",
      "For episode 3950 the finale reward-to-go is 9.0\n",
      "For episode 3960 the finale reward-to-go is 10.0\n",
      "For episode 3970 the finale reward-to-go is 10.0\n",
      "For episode 3980 the finale reward-to-go is 9.0\n",
      "For episode 3990 the finale reward-to-go is 10.0\n",
      "For episode 4000 the finale reward-to-go is 10.0\n",
      "For episode 4010 the finale reward-to-go is 9.0\n",
      "For episode 4020 the finale reward-to-go is 10.0\n",
      "For episode 4030 the finale reward-to-go is 10.0\n",
      "For episode 4040 the finale reward-to-go is 9.0\n",
      "For episode 4050 the finale reward-to-go is 9.0\n",
      "For episode 4060 the finale reward-to-go is 10.0\n",
      "For episode 4070 the finale reward-to-go is 9.0\n",
      "For episode 4080 the finale reward-to-go is 8.0\n",
      "For episode 4090 the finale reward-to-go is 11.0\n",
      "For episode 4100 the finale reward-to-go is 10.0\n",
      "For episode 4110 the finale reward-to-go is 9.0\n",
      "For episode 4120 the finale reward-to-go is 10.0\n",
      "For episode 4130 the finale reward-to-go is 10.0\n",
      "For episode 4140 the finale reward-to-go is 10.0\n",
      "For episode 4150 the finale reward-to-go is 9.0\n",
      "For episode 4160 the finale reward-to-go is 9.0\n",
      "For episode 4170 the finale reward-to-go is 10.0\n",
      "For episode 4180 the finale reward-to-go is 8.0\n",
      "For episode 4190 the finale reward-to-go is 9.0\n",
      "For episode 4200 the finale reward-to-go is 10.0\n",
      "For episode 4210 the finale reward-to-go is 10.0\n",
      "For episode 4220 the finale reward-to-go is 10.0\n",
      "For episode 4230 the finale reward-to-go is 9.0\n",
      "For episode 4240 the finale reward-to-go is 10.0\n",
      "For episode 4250 the finale reward-to-go is 10.0\n",
      "For episode 4260 the finale reward-to-go is 9.0\n",
      "For episode 4270 the finale reward-to-go is 9.0\n",
      "For episode 4280 the finale reward-to-go is 10.0\n",
      "For episode 4290 the finale reward-to-go is 8.0\n",
      "For episode 4300 the finale reward-to-go is 9.0\n",
      "For episode 4310 the finale reward-to-go is 8.0\n",
      "For episode 4320 the finale reward-to-go is 9.0\n",
      "For episode 4330 the finale reward-to-go is 10.0\n",
      "For episode 4340 the finale reward-to-go is 8.0\n",
      "For episode 4350 the finale reward-to-go is 9.0\n",
      "For episode 4360 the finale reward-to-go is 8.0\n",
      "For episode 4370 the finale reward-to-go is 10.0\n",
      "For episode 4380 the finale reward-to-go is 10.0\n",
      "For episode 4390 the finale reward-to-go is 10.0\n",
      "For episode 4400 the finale reward-to-go is 9.0\n",
      "For episode 4410 the finale reward-to-go is 9.0\n",
      "For episode 4420 the finale reward-to-go is 8.0\n",
      "For episode 4430 the finale reward-to-go is 10.0\n",
      "For episode 4440 the finale reward-to-go is 9.0\n",
      "For episode 4450 the finale reward-to-go is 9.0\n",
      "For episode 4460 the finale reward-to-go is 10.0\n",
      "For episode 4470 the finale reward-to-go is 10.0\n",
      "For episode 4480 the finale reward-to-go is 8.0\n",
      "For episode 4490 the finale reward-to-go is 10.0\n",
      "For episode 4500 the finale reward-to-go is 9.0\n",
      "For episode 4510 the finale reward-to-go is 9.0\n",
      "For episode 4520 the finale reward-to-go is 10.0\n",
      "For episode 4530 the finale reward-to-go is 11.0\n",
      "For episode 4540 the finale reward-to-go is 9.0\n",
      "For episode 4550 the finale reward-to-go is 8.0\n",
      "For episode 4560 the finale reward-to-go is 9.0\n",
      "For episode 4570 the finale reward-to-go is 9.0\n",
      "For episode 4580 the finale reward-to-go is 9.0\n",
      "For episode 4590 the finale reward-to-go is 9.0\n",
      "For episode 4600 the finale reward-to-go is 9.0\n",
      "For episode 4610 the finale reward-to-go is 9.0\n",
      "For episode 4620 the finale reward-to-go is 9.0\n",
      "For episode 4630 the finale reward-to-go is 9.0\n",
      "For episode 4640 the finale reward-to-go is 9.0\n",
      "For episode 4650 the finale reward-to-go is 10.0\n",
      "For episode 4660 the finale reward-to-go is 8.0\n",
      "For episode 4670 the finale reward-to-go is 8.0\n",
      "For episode 4680 the finale reward-to-go is 9.0\n",
      "For episode 4690 the finale reward-to-go is 9.0\n",
      "For episode 4700 the finale reward-to-go is 10.0\n",
      "For episode 4710 the finale reward-to-go is 10.0\n",
      "For episode 4720 the finale reward-to-go is 10.0\n",
      "For episode 4730 the finale reward-to-go is 8.0\n",
      "For episode 4740 the finale reward-to-go is 10.0\n",
      "For episode 4750 the finale reward-to-go is 9.0\n",
      "For episode 4760 the finale reward-to-go is 9.0\n",
      "For episode 4770 the finale reward-to-go is 9.0\n",
      "For episode 4780 the finale reward-to-go is 9.0\n",
      "For episode 4790 the finale reward-to-go is 10.0\n",
      "For episode 4800 the finale reward-to-go is 10.0\n",
      "For episode 4810 the finale reward-to-go is 10.0\n",
      "For episode 4820 the finale reward-to-go is 10.0\n",
      "For episode 4830 the finale reward-to-go is 10.0\n",
      "For episode 4840 the finale reward-to-go is 9.0\n",
      "For episode 4850 the finale reward-to-go is 10.0\n",
      "For episode 4860 the finale reward-to-go is 10.0\n",
      "For episode 4870 the finale reward-to-go is 9.0\n",
      "For episode 4880 the finale reward-to-go is 9.0\n",
      "For episode 4890 the finale reward-to-go is 10.0\n",
      "For episode 4900 the finale reward-to-go is 10.0\n",
      "For episode 4910 the finale reward-to-go is 10.0\n",
      "For episode 4920 the finale reward-to-go is 9.0\n",
      "For episode 4930 the finale reward-to-go is 9.0\n",
      "For episode 4940 the finale reward-to-go is 10.0\n",
      "For episode 4950 the finale reward-to-go is 10.0\n",
      "For episode 4960 the finale reward-to-go is 9.0\n",
      "For episode 4970 the finale reward-to-go is 9.0\n",
      "For episode 4980 the finale reward-to-go is 10.0\n",
      "For episode 4990 the finale reward-to-go is 9.0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "problem = \"CartPole-v1\"\n",
    "env = gym.make(problem)\n",
    "\n",
    "agent = AC(ALR = 2e-2, CLR = 3e-2)\n",
    "agent.num_states = 4\n",
    "agent.num_actions = 2\n",
    "\n",
    "actor_model, critic_model, critic_optimizer, actor_optimizer = agent.initialize()\n",
    "\n",
    "MAX_EPISODES = 5000\n",
    "\n",
    "buffer = Buffer(agent, 4)\n",
    "Gt = 0\n",
    "\n",
    "for ep in range(MAX_EPISODES):\n",
    "    prev_state = env.reset()\n",
    "    episodic_reward = 0\n",
    "    while True:\n",
    "        tf_prev_state = tf.expand_dims(tf.convert_to_tensor(prev_state), 0)\n",
    "        prob = agent.make_distributions(actor_model, tf_prev_state)\n",
    "        action = agent.sample_action(actor_model, tf_prev_state)\n",
    "        state, reward, done, _ = env.step(action[0])\n",
    "        \n",
    "        \n",
    "        Gt += reward\n",
    "        \n",
    "        \n",
    "        buffer.record([prev_state, prob, Gt, state])\n",
    "        \n",
    "        \n",
    "        prev_state = state\n",
    "        env.render()\n",
    "        \n",
    "        if done:\n",
    "            buffer.learn(agent)\n",
    "            if ep % 10 == 0:\n",
    "                print(\"For episode {} the finale reward-to-go is {}\".format(ep, Gt))\n",
    "            Gt = 0\n",
    "            buffer.forget()\n",
    "            break\n",
    "\n",
    "        if Gt > 200:\n",
    "            print('Goal is reached! saving results..')\n",
    "            actor_model.save_weights(\"cartpole_actor.h5\")\n",
    "            critic_model.save_weights(\"cartpole_critic.h5\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b43d592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613b123f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
